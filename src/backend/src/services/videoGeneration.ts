import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import { createAzureClient, AzureConfig } from './azureClient';
import { preprocessImage } from './imageProcessor';

/**
 * è§†é¢‘ç”Ÿæˆå‚æ•°æ¥å£
 */
export interface VideoGenerationParams {
  model: string;
  prompt?: string;
  imagePath?: string;
  resolution: string; // e.g., "1280x720"
  duration: number; // seconds
}

/**
 * è§†é¢‘ç”Ÿæˆç»“æœæ¥å£
 */
export interface VideoGenerationResult {
  id: string;
  status: 'queued' | 'in_progress' | 'completed' | 'failed';
  progress?: number;
  videoUrl?: string;
  error?: string;
}

/**
 * æ–‡æœ¬ç”Ÿæˆè§†é¢‘
 * @param client OpenAI å®¢æˆ·ç«¯
 * @param params ç”Ÿæˆå‚æ•°
 * @returns è§†é¢‘ç”Ÿæˆä»»åŠ¡ID
 */
export async function generateTextToVideo(
  client: OpenAI,
  params: VideoGenerationParams
): Promise<string> {
  if (!params.prompt) {
    throw new Error('Prompt is required for text-to-video generation');
  }

  console.log(`ğŸ¬ Generating text-to-video with prompt: "${params.prompt}"`);
  console.log(`   Model: ${params.model}, Resolution: ${params.resolution}, Duration: ${params.duration}s`);

  try {
    const response = await client.videos.create({
      model: params.model as any,
      prompt: params.prompt,
      size: params.resolution as any,
      seconds: params.duration.toString() as any,
    });

    console.log(`âœ… Video generation task created: ${response.id}`);
    return response.id;
  } catch (error: any) {
    console.error('âŒ Failed to create video generation task:', error);
    throw new Error(`Video generation failed: ${error.message}`);
  }
}

/**
 * å›¾åƒç”Ÿæˆè§†é¢‘
 * @param client OpenAI å®¢æˆ·ç«¯
 * @param params ç”Ÿæˆå‚æ•°
 * @returns è§†é¢‘ç”Ÿæˆä»»åŠ¡ID
 */
export async function generateImageToVideo(
  client: OpenAI,
  params: VideoGenerationParams
): Promise<string> {
  if (!params.imagePath) {
    throw new Error('Image path is required for image-to-video generation');
  }

  if (!fs.existsSync(params.imagePath)) {
    throw new Error(`Image file not found: ${params.imagePath}`);
  }

  console.log(`ğŸ–¼ï¸ Generating image-to-video with image: ${params.imagePath}`);
  console.log(`   Prompt: "${params.prompt || 'N/A'}"`);
  console.log(`   Model: ${params.model}, Resolution: ${params.resolution}, Duration: ${params.duration}s`);

  try {
    // é¢„å¤„ç†å›¾ç‰‡ï¼šè°ƒæ•´å°ºå¯¸ä»¥åŒ¹é…è§†é¢‘å‚æ•°
    const processedImagePath = await preprocessImage(params.imagePath, params.resolution);
    
    // è¯»å–å›¾åƒæ–‡ä»¶å†…å®¹å¹¶ç¡®å®š MIME ç±»å‹
    const fileExtension = path.extname(processedImagePath).toLowerCase();
    const mimeTypes: Record<string, string> = {
      '.jpg': 'image/jpeg',
      '.jpeg': 'image/jpeg',
      '.png': 'image/png',
      '.gif': 'image/gif',
      '.webp': 'image/webp',
    };
    const mimeType = mimeTypes[fileExtension] || 'application/octet-stream';
    
    // ä½¿ç”¨ toFile åˆ›å»ºæ­£ç¡®çš„æ–‡ä»¶å¯¹è±¡
    const { toFile } = await import('openai/uploads');
    const fileBuffer = fs.readFileSync(processedImagePath);
    const fileName = path.basename(processedImagePath);
    const imageFile = await toFile(fileBuffer, fileName, { type: mimeType });

    const response = await client.videos.create({
      model: params.model as any,
      prompt: params.prompt || '',
      size: params.resolution as any,
      seconds: params.duration.toString() as any,
      input_reference: imageFile as any,
    });

    console.log(`âœ… Video generation task created: ${response.id}`);
    return response.id;
  } catch (error: any) {
    console.error('âŒ Failed to create video generation task:', error);
    throw new Error(`Video generation failed: ${error.message}`);
  }
}

/**
 * è·å–è§†é¢‘ç”Ÿæˆä»»åŠ¡çŠ¶æ€
 * @param client OpenAI å®¢æˆ·ç«¯
 * @param videoId è§†é¢‘ä»»åŠ¡ID
 * @returns ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
 */
export async function getVideoStatus(
  client: OpenAI,
  videoId: string
): Promise<VideoGenerationResult> {
  try {
    const video = await client.videos.retrieve(videoId);

    const result: VideoGenerationResult = {
      id: video.id,
      status: video.status as any,
      progress: (video as any).progress || 0,
    };

    // å¦‚æœä»»åŠ¡æˆåŠŸå®Œæˆï¼Œè·å–è§†é¢‘ URL
    if (video.status === 'completed' && (video as any).output?.data?.[0]?.url) {
      result.videoUrl = (video as any).output.data[0].url;
    }

    // å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œè·å–é”™è¯¯ä¿¡æ¯
    if (video.status === 'failed' && (video as any).error) {
      result.error = (video as any).error.message || 'Unknown error';
    }

    return result;
  } catch (error: any) {
    console.error(`âŒ Failed to retrieve video status for ${videoId}:`, error);
    throw new Error(`Failed to get video status: ${error.message}`);
  }
}

/**
 * è½®è¯¢è§†é¢‘ç”ŸæˆçŠ¶æ€ç›´åˆ°å®Œæˆ
 * @param client OpenAI å®¢æˆ·ç«¯
 * @param videoId è§†é¢‘ä»»åŠ¡ID
 * @param onProgress è¿›åº¦å›è°ƒå‡½æ•°
 * @param pollInterval è½®è¯¢é—´éš”ï¼ˆæ¯«ç§’ï¼‰
 * @returns æœ€ç»ˆçš„ä»»åŠ¡çŠ¶æ€
 */
export async function pollVideoStatus(
  client: OpenAI,
  videoId: string,
  onProgress?: (progress: number, status: string) => void,
  pollInterval: number = 2000
): Promise<VideoGenerationResult> {
  console.log(`ğŸ”„ Starting to poll video status for ${videoId}`);

  while (true) {
    const result = await getVideoStatus(client, videoId);

    // è°ƒç”¨è¿›åº¦å›è°ƒ
    if (onProgress && result.progress !== undefined) {
      onProgress(result.progress, result.status);
    }

    // å¦‚æœä»»åŠ¡å®Œæˆï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰ï¼Œè¿”å›ç»“æœ
    if (result.status === 'completed' || result.status === 'failed') {
      console.log(`âœ… Video generation ${result.status} for ${videoId}`);
      return result;
    }

    // ç­‰å¾…åç»§ç»­è½®è¯¢
    await new Promise(resolve => setTimeout(resolve, pollInterval));
  }
}
